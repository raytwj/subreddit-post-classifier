{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"http://imgur.com/1ZcRyrc.png\" style=\"float: left; margin: 20px; height: 55px\">\n",
    "\n",
    "# Project 3: Application Programming Interface, Natural Language Processing, & Classification Modelling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Contents:\n",
    "#### Part 1 (of 3)\n",
    "- [Executive Summary](#Executive-Summary)\n",
    "- [Problem Statement](#Problem-Statement)\n",
    "- [Background & Research](#Background-&-Research)\n",
    "- [Data Collection](#Data-Collection)\n",
    "- Data Wrangling\n",
    "- Exploration & Visualisation\n",
    "- Pre-Processing & Modelling\n",
    "- Results & Analysis\n",
    "- Recommendations & Conclusions\n",
    "- References"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Executive Summary"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A cryptocurrency is a digital currency that is secured by cryptography. Bitcoin and Ethereum are the two largest cryptocurrencies by market capitalization as of this moment. While the top two coins share some similarities, they are also different in many ways. Investors and traders who wish to know more about these two top cryptocurrencies may find it difficult to grasp the many terminologies and jargons used in this field. A natural language processing classifier will be trained on posts from the two respective subreddits. It will learn to identify keywords that are more commonly associated with or are unique to each coin. This will be used to help businesses and enterprises develop an efficient and sophisticated query-answering and routing algorithm for their online chatbot to help handle the large number of enquiries. A total of 6 vectorizer-model combinations were evaluated. The vectorizers considered were Count Vectorizer and Tfidf Vectorizer. The models considered were Multinomial Naive Bayes, K-Nearest Neighbours, and Logistic Regression. Each combination was placed in a pipeline and then passed into a grid search cv. Evaluation of the combinations was conducted using 2 metrics: accuracy and receiver operating characteristic area under curve. All in all, Tfidf Vectorizer-Logistic Regression performed the best. Just on the testing dataset alone, it scored the highest accuracy (0.884) and receiver operating characteristic area under curve (0.950). The top 3 words that predicted a post to be from the Bitcoin subreddit were ‘bitcoin’, ‘btc’, and ‘lightning’. The top 3 words that predicted a post to be from the Ethereum subreddit were ‘ethereum’, ‘eth’, and ‘gas’. With the top words that the classifier has found for each subreddit, a minimum viable product can be designed. In its implementation, this chatbot will pick up on the keywords in a user-submitted message and try to identify whether the query pertains to Bitcoin or Ethereum. It will then give a suitable answer or route the message to the right customer service representative for further management."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Problem Statement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This project aims to help businesses and enterprises in the cryptocurrency space (e.g. news provider, brokerage platforms, coin vaults, mining pools) develop an efficient and sophisticated query-answering and routing algorithm for their online chatbot to help handle the large number of enquiries received from site visitors on a daily basis and reduce the burden on customer service operatives. The goal is to empower the chatbot to be able to accurately determine the nature of the enquiry and return an appropriate answer; where it is unable to do so, it will categorise the class of the enquiry and route to the relevant operative. For this to happen, the chatbot needs to (for a start) know how to recognise keywords from two well-known cryptocurrencies (Bitcoin and Ethereum) with the help of a natural language processing classifier trained on posts from the two respective subreddits."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Background & Research"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A cryptocurrency is a digital currency that is secured by cryptography. It can be transferred between users or, in certain permitted situations, be exchanged for goods and services. These online transactions are verified and recorded on an online ledger, known as a blockchain, that is enforced by a decentralised network of computers.\n",
    "([source](https://www.investopedia.com/terms/c/cryptocurrency.asp)) Bitcoin and Ethereum are the two largest cryptocurrencies by market capitalization as of this moment. ([source](https://www.nerdwallet.com/article/investing/cryptocurrency-7-things-to-know)) Bitcoin has been around since 2009 whereas Ethereum was first introduced into circulation in 2015. ([source](https://bernardmarr.com/what-is-the-difference-between-bitcoin-and-ethereum/)) Interest in cryptocurrencies has skyrocketed in recent years, with total fund inflows into cryptocurrency products hitting USD 5.6 billion in 2020, a jump of more than 600% compared to 2019. ([source](https://www.reuters.com/article/us-crypto-currencies-flows-idUSKBN28V2OE)) Most who are new to cryptocurrency would have heard of Bitcoin and Ethereum, as shown by the first question asked in this consumer insights survey on crypto assets. ([source](https://www.oecd.org/financial/education/consumer-insights-survey-on-cryptoassets.pdf)) While the top two coins share some similarities, they are also different in many ways. ([source](https://www.bloomberg.com/news/articles/2021-05-09/bitcoin-and-ethereum-how-are-they-different-quicktake)) Investors and traders who wish to know more about these two top cryptocurrencies may find it difficult to grasp the many terminologies and jargons used in this field. A natural language processing classifier will be used to learn and identify keywords that are more commonly associated with or are unique to each coin so as to lend clarity on the distinctions between the two."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Collection"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Import Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import requests\n",
    "import time\n",
    "\n",
    "pd.set_option('display.max.columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Posts From Bitcoin Subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 1: Status Code 200\n",
      "Repetition 2: Status Code 200\n",
      "Repetition 3: Status Code 200\n",
      "Repetition 4: Status Code 200\n",
      "Repetition 5: Status Code 200\n",
      "Repetition 6: Status Code 200\n",
      "Repetition 7: Status Code 200\n",
      "Repetition 8: Status Code 200\n",
      "Repetition 9: Status Code 200\n",
      "Repetition 10: Status Code 200\n",
      "Repetition 11: Status Code 200\n",
      "Repetition 12: Status Code 200\n",
      "Repetition 13: Status Code 200\n",
      "Repetition 14: Status Code 200\n",
      "Repetition 15: Status Code 200\n",
      "Repetition 16: Status Code 200\n",
      "Repetition 17: Status Code 200\n",
      "Repetition 18: Status Code 200\n",
      "Repetition 19: Status Code 200\n",
      "Repetition 20: Status Code 200\n",
      "Repetition 21: Status Code 200\n",
      "Repetition 22: Status Code 200\n",
      "Repetition 23: Status Code 200\n",
      "Repetition 24: Status Code 200\n",
      "Repetition 25: Status Code 200\n",
      "Repetition 26: Status Code 200\n",
      "Repetition 27: Status Code 200\n",
      "Repetition 28: Status Code 200\n",
      "Repetition 29: Status Code 200\n",
      "Repetition 30: Status Code 200\n",
      "Repetition 31: Status Code 200\n",
      "Repetition 32: Status Code 200\n",
      "Repetition 33: Status Code 200\n",
      "Repetition 34: Status Code 200\n",
      "Repetition 35: Status Code 200\n",
      "Repetition 36: Status Code 200\n",
      "Repetition 37: Status Code 200\n",
      "Repetition 38: Status Code 200\n",
      "Repetition 39: Status Code 200\n",
      "Repetition 40: Status Code 200\n",
      "Repetition 41: Status Code 200\n",
      "Repetition 42: Status Code 200\n",
      "Repetition 43: Status Code 200\n",
      "Repetition 44: Status Code 200\n",
      "Repetition 45: Status Code 200\n",
      "Repetition 46: Status Code 200\n",
      "Repetition 47: Status Code 200\n",
      "Repetition 48: Status Code 200\n",
      "Repetition 49: Status Code 200\n",
      "Repetition 50: Status Code 200\n"
     ]
    }
   ],
   "source": [
    "# get posts from bitcoin subreddit and place in a dataframe\n",
    "# max size of posts per request using pushshift api is 100\n",
    "# so to get the desired no of posts (5000) i have to iterate 50 times\n",
    "# the timestamp was decided in unison to be 1626939127\n",
    "# so that all group members would start from the same post and get every post before that\n",
    "\n",
    "url = 'https://api.pushshift.io/reddit/search/submission'\n",
    "\n",
    "timestamp = 1626939127\n",
    "repetitions = 50\n",
    "pdf_btc = pd.DataFrame()\n",
    "\n",
    "for repetition in range(repetitions):\n",
    "    \n",
    "    params = {'subreddit': 'Bitcoin', 'size': 100, 'before': timestamp}\n",
    "    \n",
    "    response = requests.get(url, params)\n",
    "    print(f'Repetition {repetition + 1}: Status Code {response.status_code}')\n",
    "    \n",
    "    data = response.json()\n",
    "    posts = data['data']\n",
    "    \n",
    "    df = pd.DataFrame(posts)\n",
    "    pdf_btc = pd.concat([pdf_btc, df])\n",
    "    timestamp = posts[-1]['created_utc']\n",
    "\n",
    "# use this code block if the api scrape keeps getting interrupted by errors\n",
    "\n",
    "# url = 'https://api.pushshift.io/reddit/search/submission'\n",
    "\n",
    "# timestamp = 1626939127\n",
    "# repetitions = 50\n",
    "# pdf_btc = pd.DataFrame()\n",
    "# count = 0\n",
    "\n",
    "# while count < repetitions:\n",
    "    \n",
    "#     params = {'subreddit': 'Bitcoin', 'size': 100, 'before': timestamp}\n",
    "    \n",
    "#     try:\n",
    "#         response = requests.get(url, params)\n",
    "#         print(f'Repetition {count + 1}: Status Code {response.status_code}')\n",
    "        \n",
    "#         data = response.json()\n",
    "#         posts = data['data']\n",
    "        \n",
    "#         df = pd.DataFrame(posts)\n",
    "#         pdf_btc = pd.concat([pdf_btc, df])\n",
    "#         timestamp = posts[-1]['created_utc']\n",
    "#         count += 1\n",
    "        \n",
    "#     except:\n",
    "#         print('Error')\n",
    "#         time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset index of dataframe\n",
    "pdf_btc.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=5000, step=1)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that index has been resetted\n",
    "pdf_btc.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export dataframe as csv file\n",
    "pdf_btc.to_csv('../data/btc_posts.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Get Posts From Ethereum Subreddit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Repetition 1: Status Code 200\n",
      "Repetition 2: Status Code 200\n",
      "Repetition 3: Status Code 200\n",
      "Repetition 4: Status Code 200\n",
      "Repetition 5: Status Code 200\n",
      "Repetition 6: Status Code 200\n",
      "Repetition 7: Status Code 200\n",
      "Repetition 8: Status Code 200\n",
      "Repetition 9: Status Code 200\n",
      "Repetition 10: Status Code 200\n",
      "Repetition 11: Status Code 200\n",
      "Repetition 12: Status Code 200\n",
      "Repetition 13: Status Code 200\n",
      "Repetition 14: Status Code 200\n",
      "Repetition 15: Status Code 200\n",
      "Repetition 16: Status Code 200\n",
      "Repetition 17: Status Code 200\n",
      "Repetition 18: Status Code 200\n",
      "Repetition 19: Status Code 200\n",
      "Repetition 20: Status Code 200\n",
      "Repetition 21: Status Code 200\n",
      "Repetition 22: Status Code 200\n",
      "Repetition 23: Status Code 200\n",
      "Repetition 24: Status Code 200\n",
      "Repetition 25: Status Code 200\n",
      "Repetition 26: Status Code 200\n",
      "Repetition 27: Status Code 200\n",
      "Repetition 28: Status Code 200\n",
      "Repetition 29: Status Code 200\n",
      "Repetition 30: Status Code 200\n",
      "Repetition 31: Status Code 200\n",
      "Repetition 32: Status Code 200\n",
      "Repetition 33: Status Code 200\n",
      "Repetition 34: Status Code 200\n",
      "Repetition 35: Status Code 200\n",
      "Repetition 36: Status Code 200\n",
      "Repetition 37: Status Code 200\n",
      "Repetition 38: Status Code 200\n",
      "Repetition 39: Status Code 200\n",
      "Repetition 40: Status Code 200\n",
      "Repetition 41: Status Code 200\n",
      "Repetition 42: Status Code 200\n",
      "Repetition 43: Status Code 200\n",
      "Repetition 44: Status Code 200\n",
      "Repetition 45: Status Code 200\n",
      "Repetition 46: Status Code 200\n",
      "Repetition 47: Status Code 200\n",
      "Repetition 48: Status Code 200\n",
      "Repetition 49: Status Code 200\n",
      "Repetition 50: Status Code 200\n",
      "Repetition 51: Status Code 200\n",
      "Repetition 52: Status Code 200\n",
      "Repetition 53: Status Code 200\n",
      "Repetition 54: Status Code 200\n",
      "Repetition 55: Status Code 200\n",
      "Repetition 56: Status Code 200\n",
      "Repetition 57: Status Code 200\n",
      "Repetition 58: Status Code 200\n",
      "Repetition 59: Status Code 200\n",
      "Repetition 60: Status Code 200\n",
      "Repetition 61: Status Code 200\n",
      "Repetition 62: Status Code 200\n",
      "Repetition 63: Status Code 200\n",
      "Repetition 64: Status Code 200\n",
      "Repetition 65: Status Code 200\n",
      "Repetition 66: Status Code 200\n",
      "Repetition 67: Status Code 200\n",
      "Repetition 68: Status Code 200\n",
      "Repetition 69: Status Code 200\n",
      "Repetition 70: Status Code 200\n",
      "Repetition 71: Status Code 200\n",
      "Repetition 72: Status Code 200\n",
      "Repetition 73: Status Code 200\n",
      "Repetition 74: Status Code 200\n",
      "Repetition 75: Status Code 200\n",
      "Repetition 76: Status Code 200\n",
      "Repetition 77: Status Code 200\n",
      "Repetition 78: Status Code 200\n",
      "Repetition 79: Status Code 200\n",
      "Repetition 80: Status Code 200\n",
      "Repetition 81: Status Code 200\n",
      "Repetition 82: Status Code 200\n",
      "Repetition 83: Status Code 200\n",
      "Repetition 84: Status Code 200\n",
      "Repetition 85: Status Code 200\n",
      "Repetition 86: Status Code 200\n",
      "Repetition 87: Status Code 200\n",
      "Repetition 88: Status Code 200\n",
      "Repetition 89: Status Code 200\n",
      "Repetition 90: Status Code 200\n",
      "Repetition 91: Status Code 200\n",
      "Repetition 92: Status Code 200\n",
      "Repetition 93: Status Code 200\n",
      "Repetition 94: Status Code 200\n",
      "Repetition 95: Status Code 200\n",
      "Repetition 96: Status Code 200\n",
      "Repetition 97: Status Code 200\n",
      "Repetition 98: Status Code 200\n",
      "Repetition 99: Status Code 200\n",
      "Repetition 100: Status Code 200\n"
     ]
    }
   ],
   "source": [
    "# get posts from ethereum subreddit and place in a dataframe\n",
    "# max size of posts per request using pushshift api is 100\n",
    "# so to get the desired no of posts (10000) i have to iterate 100 times\n",
    "# the timestamp was decided in unison to be 1626939643\n",
    "# so that all group members would start from the same post and get every post before that\n",
    "\n",
    "url = 'https://api.pushshift.io/reddit/search/submission'\n",
    "\n",
    "timestamp = 1626939643\n",
    "repetitions = 100\n",
    "pdf_eth = pd.DataFrame()\n",
    "\n",
    "for repetition in range(repetitions):\n",
    "    \n",
    "    params = {'subreddit': 'ethereum', 'size': 100, 'before': timestamp}\n",
    "    \n",
    "    response = requests.get(url, params)\n",
    "    print(f'Repetition {repetition + 1}: Status Code {response.status_code}')\n",
    "    \n",
    "    data = response.json()\n",
    "    posts = data['data']\n",
    "    \n",
    "    df = pd.DataFrame(posts)\n",
    "    pdf_eth = pd.concat([pdf_eth, df])\n",
    "    timestamp = posts[-1]['created_utc']\n",
    "\n",
    "# use this code block if the api scrape keeps getting interrupted by errors\n",
    "\n",
    "# url = 'https://api.pushshift.io/reddit/search/submission'\n",
    "\n",
    "# timestamp = 1626939643\n",
    "# repetitions = 100\n",
    "# pdf_eth = pd.DataFrame()\n",
    "# count = 0\n",
    "\n",
    "# while count < repetitions:\n",
    "    \n",
    "#     params = {'subreddit': 'ethereum', 'size': 100, 'before': timestamp}\n",
    "    \n",
    "#     try:\n",
    "#         response = requests.get(url, params)\n",
    "#         print(f'Repetition {count + 1}: Status Code {response.status_code}')\n",
    "        \n",
    "#         data = response.json()\n",
    "#         posts = data['data']\n",
    "        \n",
    "#         df = pd.DataFrame(posts)\n",
    "#         pdf_eth = pd.concat([pdf_eth, df])\n",
    "#         timestamp = posts[-1]['created_utc']\n",
    "#         count += 1\n",
    "        \n",
    "#     except:\n",
    "#         print('Error')\n",
    "#         time.sleep(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reset index of dataframe\n",
    "pdf_eth.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RangeIndex(start=0, stop=10000, step=1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# check that index has been resetted\n",
    "pdf_eth.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# export dataframe as csv file\n",
    "pdf_eth.to_csv('../data/eth_posts.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backup: Get Comments From Bitcoin Subreddit [Not Used]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# get comments from bitcoin subreddit and place in a dataframe\n",
    "# max size of comments per request using pushshift api is 100\n",
    "# so to get the desired no of comments (5000) i have to iterate 50 times\n",
    "# the timestamp was decided in unison to be 1626939127\n",
    "# so that all group members would start from the same post and get every post before that\n",
    "\n",
    "# url = 'https://api.pushshift.io/reddit/search/comment'\n",
    "\n",
    "# timestamp = 1626939127\n",
    "# repetitions = 50\n",
    "# cdf_btc = pd.DataFrame()\n",
    "\n",
    "# for repetition in range(repetitions):\n",
    "    \n",
    "#     params = {'subreddit': 'Bitcoin', 'size': 100, 'before': timestamp}\n",
    "    \n",
    "#     response = requests.get(url, params)\n",
    "#     print(f'Repetition {repetition + 1}: Status Code {response.status_code}')\n",
    "    \n",
    "#     data = response.json()\n",
    "#     posts = data['data']\n",
    "    \n",
    "#     df = pd.DataFrame(posts)\n",
    "#     cdf_btc = pd.concat([cdf_btc, df])\n",
    "#     timestamp = posts[-1]['created_utc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # reset index of dataframe\n",
    "# cdf_btc.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check that index has been resetted\n",
    "# cdf_btc.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # export dataframe as csv file\n",
    "# cdf_btc.to_csv('../data/btc_comments.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Backup: Get Comments From Ethereum Subreddit [Not Used]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# get comments from ethereum subreddit and place in a dataframe\n",
    "# max size of comments per request using pushshift api is 100\n",
    "# so to get the desired no of posts (10000) i have to iterate 100 times\n",
    "# the timestamp was decided in unison to be 1626939643\n",
    "# so that all group members would start from the same post and get every post before that\n",
    "\n",
    "# url = 'https://api.pushshift.io/reddit/search/comment'\n",
    "\n",
    "# timestamp = 1626939643\n",
    "# repetitions = 100\n",
    "# cdf_eth = pd.DataFrame()\n",
    "\n",
    "# for repetition in range(repetitions):\n",
    "    \n",
    "#     params = {'subreddit': 'ethereum', 'size': 100, 'before': timestamp}\n",
    "    \n",
    "#     response = requests.get(url, params)\n",
    "#     print(f'Repetition {repetition + 1}: Status Code {response.status_code}')\n",
    "    \n",
    "#     data = response.json()\n",
    "#     posts = data['data']\n",
    "    \n",
    "#     df = pd.DataFrame(posts)\n",
    "#     cdf_eth = pd.concat([cdf_eth, df])\n",
    "#     timestamp = posts[-1]['created_utc']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # reset index of dataframe\n",
    "# cdf_eth.reset_index(drop=True, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # check that index has been resetted\n",
    "# cdf_eth.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # export dataframe as csv file\n",
    "# cdf_eth.to_csv('../data/eth_comments.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
